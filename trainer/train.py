import torch
import torch.nn as nn

import logging
import itertools

import torch.nn.functional as F

logger = logging.getLogger(__name__)
from util.optimizer_scheduler import initialize_optimizer, initialize_scheduler
from util.metric_util import  tensor2img, calculate_psnr, calculate_ssim

import matplotlib
matplotlib.use('Agg')


from loss.loss import  PerceptualLoss,EdgeLoss
import time
import os
import torchvision.utils as vutils
from pytorch_msssim import SSIM, MS_SSIM
class Trainer():
    def __init__(self, args, models, dataloaders, ckp):
        self.args = args
        self.ckp = ckp
        self.train_dataloader, self.test_dataloader = dataloaders  # è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åŠ è½½å™¨
        # è®¾å®šæµ‹è¯•æ—¶æœ€å¤šä½¿ç”¨çš„æ•°æ®é›†å›¾ç‰‡æ•°
        self.max_evaluation_count = self.args.data.max_evaluation_count
        # æŒ‡å®šä½¿ç”¨ GPU
        self.selected_gpus = args.train.gpus

        # åˆ¤æ–­è®¾å¤‡
        if torch.cuda.is_available():
            self.device = torch.device(f"cuda:{self.selected_gpus[0]}")
            torch.cuda.set_device(self.selected_gpus[0])
        else:
            self.device = torch.device("cpu")

        # å¤š GPU é€‚é…
        self.models = {}
        for name, model in models.items():
            if torch.cuda.device_count() > 1 and torch.cuda.is_available() and len(self.selected_gpus) > 1:
                model = nn.DataParallel(model, device_ids=self.selected_gpus)
            model.to(self.device)
            self.models[name] = model

        # å®šä¹‰ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        self.optimizers = {name: initialize_optimizer(args, model, name) for name, model in self.models.items()}
        self.schedulers = {name: initialize_scheduler(args, optimizer, name) for name, optimizer in
                           self.optimizers.items()}

        self.existing_step = 0  # è®°å½•å·²æœ‰çš„è®­ç»ƒæ­¥æ•°
        self.current_loss = []  # å­˜å‚¨å½“å‰çš„æŸå¤±å€¼
        # åˆå§‹åŒ–æ•°æ®è¿­ä»£å™¨
        self.loader_train_iter = iter(self.train_dataloader)

        # ----------------------------------
        # å†…å®¹æ„ŸçŸ¥loss
        self.criterionPL = PerceptualLoss(device=self.device, model_path=self.args.train.vgg_model_path)
        # é²æ£’æ€§L1loss
        self.criterionML = nn.L1Loss().to(self.device)
        # è¾¹ç¼˜loss
        self.criterionEDGE = EdgeLoss(device=self.device).to(self.device)
        ### Model Loading
        self.load_previous_ckp(models=self.models)

        # è®¡ç®—æµ‹è¯•è½®æ•°å’Œä¿å­˜æ¨¡å‹è½®æ•°
        self.test_every = 1
        self.best_psnr = 0

        self.all_best_psnr = 0
        self.best_model_root = os.path.join(self.ckp.log_dir, '0.pth')
        self.all_best_model_root = os.path.join(self.ckp.log_dir, f"all_best_0.pt")

    def load_previous_ckp(self, models=None):
        if self.ckp is not None:
            if models is None:
                models = self.models

            self.existing_step, self.current_loss = self.ckp.load_checkpoint(models, self.optimizers, self.schedulers)

            if self.existing_step > 0:
                logger.info('Resuming training.')

    def train(self):
        now_iter = 1
        last_print_time = time.time()  # â±ï¸ è®°å½•ä¸Šä¸€æ¬¡ print_loss çš„æ—¶é—´
        while now_iter <= self.args.train.max_iter:
            self.models['MSLKAD'].train()
            try:
                lr, hr = next(self.loader_train_iter)
            except StopIteration:
                self.loader_train_iter = iter(self.train_dataloader)
                logger.info(f'Iter {now_iter} Resuming Training Data.')
                # æ¯ä¸‰ä¸ªæµ‹å…¨éƒ¨
                if self.test_every % 1 == 0 :
                    self.testall(now_iter)

                lr, hr = next(self.loader_train_iter)
                self.test_every += 1

            lr_tensor = lr.to(self.device, dtype=torch.float32)
            hr_tensor = hr.to(self.device, dtype=torch.float32)

            out = self.models['MSLKAD'](lr_tensor)

            self.optimizers['MSLKAD'].zero_grad()

            loss_PL = self.criterionPL(out, hr_tensor.detach())

            loss_ML = self.criterionML(out, hr_tensor)
            loss_edge = self.criterionEDGE(out, hr_tensor)
            # loss_fft = self.criterionFFT(out, hr_tensor)
            loss_G = loss_ML +  0.7 *loss_PL + 0.15 * loss_edge

            loss_G.backward()
            self.optimizers['MSLKAD'].step()
            self.schedulers['MSLKAD'].step()

            if now_iter % self.args.train.print_lr == 0:
                current_lr = self.optimizers['MSLKAD'].param_groups[0]['lr']
                logger.info(f"Current LR: {current_lr:.6f}")

            # æ¯ print_loss æ¬¡æ‰“å°ä¸€æ¬¡æŸå¤±å’Œè€—æ—¶ï¼ˆåŒºé—´è€—æ—¶ï¼‰
            if now_iter % self.args.train.print_loss == 0:
                current_time = time.time()
                interval_time = current_time - last_print_time
                interval_str = time.strftime('%H:%M:%S', time.gmtime(interval_time))

                logger.info(
                    'Iter [{:04d}/{}]\t'
                    'Raw Losses [PL: {:.3f} | ML: {:.3f} | Edge: {:.3f} ]  '
                    'Weighted Total: {:.3f}\t'
                    'Time: {}'.format(
                        now_iter, self.args.train.max_iter,
                        loss_PL.item(), loss_ML.item(), loss_edge.item(),
                        loss_G.item(),
                        interval_str
                    )
                )

                last_print_time = current_time  # ğŸ”„ æ›´æ–°ä¸ºæœ¬æ¬¡æ—¶é—´

            if now_iter == self.args.train.max_iter:
                self.save_ckp(now_iter, self.models)
            now_iter += 1

    def test(self, now_iter):
        self.models['MSLKAD'].eval()
        with torch.no_grad():
            eval_psnr = 0
            eval_ssim = 0
            max_test_samples = self.max_evaluation_count
            start_time = time.time()

            for lr, hr, filename in itertools.islice(self.test_dataloader, max_test_samples):
                lr_tensor = lr.clone().detach().to(dtype=torch.float32, device=self.device)
                height, width = lr_tensor.shape[2], lr_tensor.shape[3]
                out = self.models['MSLKAD'](lr_tensor)

                sr = out[:, :, :height, :width]  # é˜²æ­¢æ¨¡å‹è¾“å‡ºç•¥å¤§ï¼ˆä¿é™©èµ·è§ä¿ç•™ï¼‰

                sr = tensor2img(sr)
                hr = tensor2img(hr)

                now_psnr = calculate_psnr(sr, hr,crop_border=0,input_order="HWC")
                now_ssim = calculate_ssim(sr, hr,crop_border=0,input_order="HWC")

                eval_psnr += now_psnr
                eval_ssim += now_ssim

            end_time = time.time()
            test_time = end_time - start_time

            avg_psnr = eval_psnr / max_test_samples
            avg_ssim = eval_ssim / max_test_samples

            # æ›´æ–°æœ€ä¼˜æ¨¡å‹é€»è¾‘
            if avg_psnr > self.best_psnr:
                logger.info(f"[now_iter {now_iter}] New best model found! PSNR: {avg_psnr:.3f}, SSIM: {avg_ssim:.4f}")

                # åˆ é™¤æ—§çš„æœ€ä¼˜æ¨¡å‹
                if os.path.exists(self.best_model_root):
                    os.remove(self.best_model_root)

                # ä¿å­˜æ–°çš„æœ€ä¼˜æ¨¡å‹
                best_model_path = os.path.join(self.ckp.log_dir, f"{now_iter}.pt")
                self.save_ckp(now_iter, models=self.models)

                # æ›´æ–°çŠ¶æ€
                self.best_psnr = avg_psnr

                self.best_model_root = best_model_path
                # å‘ç°æœ€å¥½çš„æµ‹è¯•å…¨éƒ¨
                #self.testall(now_iter)

            logger.info('[now_iter {}]\tPSNR: {:.3f} SSIM: {:.4f} | Test Time: {:.2f}s'.format(
                self.args.data.test_data,
                avg_psnr,
                avg_ssim,
                test_time
            ))

    def tile_forward(self, model, input_tensor, tile_size=256, tile_overlap=32):
        """
        æ»‘çª—æ¨ç†ï¼ˆæ— ç¼©æ”¾ï¼‰ï¼Œç”¨äºå¤§å›¾åˆ†å—å¤„ç†ã€‚

        Args:
            model: ç½‘ç»œæ¨¡å‹
            input_tensor: è¾“å…¥å›¾åƒ tensorï¼Œå½¢çŠ¶ [B, C, H, W]
            tile_size: æ¯å— tile çš„è¾¹é•¿
            tile_overlap: é‚»è¿‘ tile çš„é‡å åŒºåŸŸ

        Returns:
            output_tensor: æ‹¼æ¥åçš„å®Œæ•´å›¾åƒï¼ˆä¸è¾“å…¥å°ºå¯¸ä¸€è‡´ï¼‰
        """
        B, C, H, W = input_tensor.shape
        stride = tile_size - tile_overlap

        E = torch.zeros_like(input_tensor)  # æ‹¼æ¥è¾“å‡º
        W_map = torch.zeros_like(input_tensor)  # åŠ æƒèåˆè®¡æ•°

        h_idx_list = list(range(0, H - tile_size, stride)) + [H - tile_size] if H > tile_size else [0]
        w_idx_list = list(range(0, W - tile_size, stride)) + [W - tile_size] if W > tile_size else [0]

        for y in h_idx_list:
            for x in w_idx_list:
                in_patch = input_tensor[:, :, y:y + tile_size, x:x + tile_size]
                patch_h, patch_w = in_patch.shape[2:]

                # patch å¯èƒ½ä¸è¶³ tile_sizeï¼Œéœ€ pad
                pad_bottom = tile_size - patch_h
                pad_right = tile_size - patch_w
                if pad_bottom > 0 or pad_right > 0:
                    in_patch = F.pad(in_patch, (0, pad_right, 0, pad_bottom), mode='reflect')

                with torch.no_grad():
                    out_patch = model(in_patch)
                    out_patch = out_patch[:, :, :patch_h, :patch_w]  # æˆªæ–­ padding åŒºåŸŸ

                E[:, :, y:y + patch_h, x:x + patch_w] += out_patch
                W_map[:, :, y:y + patch_h, x:x + patch_w] += 1

        W_map = torch.where(W_map == 0, torch.ones_like(W_map), W_map)
        return E / W_map
    def testonly(self):
        # æµ‹è¯•
        self.models['MSLKAD'].eval()
        save_dir = self.args.train.save_dir
        os.makedirs(save_dir, exist_ok=True)
        with torch.no_grad():
            for idx, (lr, hr, filename) in enumerate(self.test_dataloader):
                lr_tensor = lr.clone().detach().to(dtype=torch.float32, device=self.device)
                hr_tensor = hr.clone().detach().to(dtype=torch.float32, device=self.device)
                height, width = lr_tensor.shape[2], lr_tensor.shape[3]

                out, feature = self.models['MSLKAD'](lr_tensor, lr_tensor - hr_tensor)
                sr = out[:, :, :height, :width]

                # å¦‚æœ filename æ˜¯å­—ç¬¦ä¸²
                if isinstance(filename, (list, tuple)):
                    filename = filename[0]  # å‡è®¾ dataloader è¿”å›çš„æ˜¯ [name]

                save_path = os.path.join(save_dir, f"{os.path.splitext(os.path.basename(filename))[0]}.png")

                # å½’ä¸€åŒ–åˆ° [0,1]ï¼Œä¿å­˜å›¾ç‰‡
                sr_clamped = torch.clamp(sr, 0, 1)
                vutils.save_image(sr_clamped, save_path)
                print(f"Saved: {save_path}")
    def testall(self,now_iter):
        # æµ‹è¯•
        self.models['MSLKAD'].eval()
        with torch.no_grad():
            eval_psnr = 0
            eval_ssim = 0
            for idx, (lr, hr, filename) in enumerate(self.test_dataloader):
                lr_tensor = lr.clone().detach().to(dtype=torch.float32, device=self.device)
                height, width = lr_tensor.shape[2], lr_tensor.shape[3]

                if width > 1000 or height > 1000:
                    # ä½¿ç”¨æ»‘çª—åˆ†å—æ¨ç†ï¼Œä¸åšpadding
                    out = self.tile_forward(self.models['MSLKAD'], lr_tensor, tile_size=256, tile_overlap=32)
                else:

                    out = self.models['MSLKAD'](lr_tensor)

                sr = out[:, :, :height, :width]  # ä¿ç•™è£å‰ªï¼Œé˜²æ­¢ tile æ¨ç†è¶…å‡ºèŒƒå›´

                sr_img = tensor2img(sr)
                hr_img = tensor2img(hr)

                now_psnr = calculate_psnr(sr_img, hr_img,crop_border=0,input_order="HWC")
                now_ssim = calculate_ssim(sr_img, hr_img,crop_border=0,input_order="HWC")

                eval_psnr += now_psnr
                eval_ssim += now_ssim

                if self.args.train.test_only:
                    logger.info(f"[Sample {idx} - {filename}] PSNR: {now_psnr:.3f} | SSIM: {now_ssim:.4f}")


            avg_psnr = eval_psnr / len(self.test_dataloader)
            avg_ssim = eval_ssim / len(self.test_dataloader)
            # æ›´æ–°æœ€ä¼˜æ¨¡å‹é€»è¾‘
            if avg_psnr > self.all_best_psnr:
                logger.info(f"[now_iter {now_iter}] New best model found! PSNR: {avg_psnr:.3f}, SSIM: {avg_ssim:.4f}")

                # åˆ é™¤æ—§çš„æœ€ä¼˜æ¨¡å‹
                if os.path.exists(self.all_best_model_root):
                    os.remove(self.all_best_model_root)

                # ä¿å­˜æ–°çš„æœ€ä¼˜æ¨¡å‹
                best_model_path = os.path.join(self.ckp.log_dir, f"all_best_{now_iter}.pt")
                self.save_ckp(f"all_best_{now_iter}", models=self.models)

                # æ›´æ–°çŠ¶æ€
                self.all_best_psnr = avg_psnr

                self.all_best_model_root = best_model_path

            logger.info('[Dataset {}]\tAvg PSNR: {:.3f} Avg SSIM: {:.4f}'.format(
                self.args.data.test_data,
                avg_psnr,
                avg_ssim,
            ))


    # ä¿å­˜æ£€æŸ¥ç‚¹
    def save_ckp(self, step, models=None):
        if self.ckp is not None:
            if models is None:
                models = self.model
            self.ckp.save_checkpoint(step, self.current_loss, models, self.optimizers, self.schedulers)

    # è®°å½•å½“å‰è®­ç»ƒæ­¥æ•°
    def log_current_step(self, step):
        if self.ckp is not None:
            self.ckp.write_step(step)

    # è®°å½•ä¸­é—´è®­ç»ƒç»“æœ
    def dump_intermediate_results(self, img, fn, step):
        if self.ckp is not None:
            self.ckp.dump_intermediate_results(img, f'{fn}_{step}.png')


